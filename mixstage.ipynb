{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MogoWhite/gesture_fake_video_detection/blob/main/mixstage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYUZW6I6SmuV",
        "outputId": "e0d35c92-47da-4737-a463-fb86ebc3574c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.10\n"
          ]
        }
      ],
      "source": [
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGXCNT-2S18V",
        "outputId": "ab92da77-177c-4756-b452-b2eba04649b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU2gwu9ffn0T",
        "outputId": "b4ef9087-a0a9-41e4-bdee-d24d02dc19f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mix-stage'...\n",
            "remote: Enumerating objects: 247, done.\u001b[K\n",
            "remote: Counting objects: 100% (246/246), done.\u001b[K\n",
            "remote: Compressing objects: 100% (153/153), done.\u001b[K\n",
            "remote: Total 247 (delta 85), reused 237 (delta 81), pack-reused 1\u001b[K\n",
            "Receiving objects: 100% (247/247), 15.36 MiB | 18.12 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b master --single-branch https://github.com/chahuja/mix-stage.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwguPu5Wfs-S"
      },
      "outputs": [],
      "source": [
        "!ln -s /content/drive/MyDrive/pats/data /content/mix-stage/     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUidTFkChLe8",
        "outputId": "d496ce1c-400c-4601-e690-882df856d927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mix-stage\n",
            "Cloning into '../pycasper'...\n",
            "remote: Enumerating objects: 172, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 172 (delta 19), reused 19 (delta 6), pack-reused 140\u001b[K\n",
            "Receiving objects: 100% (172/172), 36.01 KiB | 185.00 KiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n",
            "/content/mix-stage/src\n"
          ]
        }
      ],
      "source": [
        "%cd mix-stage\n",
        "!mkdir ../pycasper\n",
        "!git clone https://github.com/chahuja/pycasper ../pycasper\n",
        "\n",
        "%cd src\n",
        "!ln -s ../../pycasper/pycasper .  ## create a symlink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBZy2msChOfZ",
        "outputId": "78eda68f-a168-46e5-db25-f78873c575e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mix-stage\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h5py==2.9.0\n",
            "  Using cached h5py-2.9.0-cp38-cp38-manylinux1_x86_64.whl (2.8 MB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.3.5)\n",
            "Collecting matplotlib==3.1.2\n",
            "  Using cached matplotlib-3.1.2-cp38-cp38-manylinux1_x86_64.whl (13.1 MB)\n",
            "Collecting scipy==1.3.2\n",
            "  Using cached scipy-1.3.2-cp38-cp38-manylinux1_x86_64.whl (25.2 MB)\n",
            "Collecting argunparse==0.1.2\n",
            "  Using cached argunparse-0.1.2-py3-none-any.whl (9.2 kB)\n",
            "Collecting librosa==0.7.0\n",
            "  Using cached librosa-0.7.0.tar.gz (1.6 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting joblib==0.14.0\n",
            "  Using cached joblib-0.14.0-py2.py3-none-any.whl (294 kB)\n",
            "Collecting transformers==2.5.1\n",
            "  Using cached transformers-2.5.1-py3-none-any.whl (499 kB)\n",
            "Collecting numpy==1.20\n",
            "  Using cached numpy-1.20.0-cp38-cp38-manylinux2010_x86_64.whl (15.4 MB)\n",
            "Collecting gensim==3.8.0\n",
            "  Using cached gensim-3.8.0.tar.gz (23.4 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prettytable==0.7.2\n",
            "  Using cached prettytable-0.7.2.zip (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nltk==3.4.5\n",
            "  Using cached nltk-3.4.5.zip (1.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp38-cp38-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.4/753.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webrtcvad==2.0.10\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch_pretrained_bert==0.6.2\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2==2.11.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 16)) (2.11.3)\n",
            "Collecting tqdm==4.48.2\n",
            "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML==5.4\n",
            "  Downloading PyYAML-5.4-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.2/662.2 KB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp38-cp38-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb==0.10.15\n",
            "  Downloading wandb-0.10.15-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from h5py==2.9.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 3)) (0.11.0)\n",
            "Collecting version-query\n",
            "  Downloading version_query-1.2.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.0->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.0->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.0->-r requirements.txt (line 6)) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.0->-r requirements.txt (line 6)) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.0->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==2.5.1->-r requirements.txt (line 8)) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==2.5.1->-r requirements.txt (line 8)) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==2.5.1->-r requirements.txt (line 8)) (3.9.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.68-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp38-cp38-manylinux1_x86_64.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart_open>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from gensim==3.8.0->-r requirements.txt (line 10)) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2==2.11.3->-r requirements.txt (line 16)) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==0.23.2->-r requirements.txt (line 19)) (3.1.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.10.15->-r requirements.txt (line 20)) (5.4.8)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.3.0-py3-none-any.whl (19 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.10.15->-r requirements.txt (line 20)) (2.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.10.15->-r requirements.txt (line 20)) (7.1.2)\n",
            "Collecting watchdog<0.10.5,>=0.8.3\n",
            "  Downloading watchdog-0.10.4.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.10.15->-r requirements.txt (line 20)) (3.19.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.38.0->librosa==0.7.0->-r requirements.txt (line 6)) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.38.0->librosa==0.7.0->-r requirements.txt (line 6)) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.38.0->librosa==0.7.0->-r requirements.txt (line 6)) (0.39.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==2.5.1->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==2.5.1->-r requirements.txt (line 8)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==2.5.1->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==2.5.1->-r requirements.txt (line 8)) (1.24.3)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.9.0->librosa==0.7.0->-r requirements.txt (line 6)) (1.15.1)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.68\n",
            "  Downloading botocore-1.29.68-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools\n",
            "  Downloading setuptools-67.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.8/dist-packages (from version-query->argunparse==0.1.2->-r requirements.txt (line 5)) (23.0)\n",
            "Collecting semver~=2.13\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.0->-r requirements.txt (line 6)) (2.21)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.38.0->librosa==0.7.0->-r requirements.txt (line 6)) (3.12.0)\n",
            "Building wheels for collected packages: librosa, gensim, prettytable, nltk, webrtcvad, subprocess32, watchdog, sacremoses, pathtools\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.0-py3-none-any.whl size=1598359 sha256=0e8c2fd4b4ee9c32480e440e6352b145e31b8a56029563fcc0f8c07c05876286\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/a2/a7/ea7703de8e54f06ddbdd455ecaa7f6d4b94b5fcfe4eb86504a\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.8.0-cp38-cp38-linux_x86_64.whl size=26617083 sha256=242907f2e70a7d7b7c39d9c197693a59702657dcec141c2e651c97167e890d90\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/d1/44/6d6dcb820e282b40ccfce6d2bb0101c24d7fffd863b2276783\n",
            "  Building wheel for prettytable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13714 sha256=4e4d777dcfe2ff9c142d1b7a80c4e967b8f0871ae654282a8977752e9b2a6a2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/6d/77/9517cb933af254f51a446f1a5ec9c2be3e45f17384940bce68\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449920 sha256=d58d6e53ad31f64881eb7af9ef89dd645db53c36fceab93b65df3a6d91d3a988\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/18/48/8fd6ec11da38406b309470566d6f099c04805d2ec61d7829e7\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp38-cp38-linux_x86_64.whl size=81045 sha256=1888cde47cd8f13834883bd3102afa357aa63c9a3a403c18b45362c9a1e36e5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e1/fc/01099a9fd0882ce84cc99eb51495812bb8a703461c2b0ca1cb\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6501 sha256=37c8b540d161659e4655a1ce292348b17cffa05ff682c8f3ce9423cd59bf512e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/69/d1/50b39b308a87998eaf5c1d9095e5a5bd2ad98501e2b7936d36\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.4-py3-none-any.whl size=74871 sha256=b7cc6f335f39fd45b23dfd087b7c5a1f480a1f0fac9c53e7b473a3cc8af14003\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/9f/05/5628e30bbbeb4f59e31aa98a59735ca3a8ca3ca4082ba83a13\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=f37d7ae680af435f09b75a36a171dd04c20336127927bec6645fc80c055c5727\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=d62d94e34db787cfea64bbd0d691437a398dc7c72c4b0edcfbf9233175e00e32\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built librosa gensim prettytable nltk webrtcvad subprocess32 watchdog sacremoses pathtools\n",
            "Installing collected packages: webrtcvad, tokenizers, sentencepiece, prettytable, pathtools, joblib, watchdog, urllib3, tqdm, torch, subprocess32, smmap, shortuuid, setuptools, semver, PyYAML, numpy, nltk, jmespath, docker-pycreds, configparser, sentry-sdk, scipy, sacremoses, matplotlib, h5py, gitdb, botocore, scikit_learn, s3transfer, GitPython, gensim, wandb, version-query, librosa, boto3, transformers, pytorch_pretrained_bert, argunparse\n",
            "  Attempting uninstall: prettytable\n",
            "    Found existing installation: prettytable 3.6.0\n",
            "    Uninstalling prettytable-3.6.0:\n",
            "      Successfully uninstalled prettytable-3.6.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.2.0\n",
            "    Uninstalling joblib-1.2.0:\n",
            "      Successfully uninstalled joblib-1.2.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.3.2 which is incompatible.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n",
            "pymc 4.1.4 requires scipy>=1.4.1, but you have scipy 1.3.2 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.3.2 which is incompatible.\n",
            "kapre 0.3.7 requires librosa>=0.7.2, but you have librosa 0.7.0 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.3.2 which is incompatible.\n",
            "jax 0.3.25 requires scipy>=1.5, but you have scipy 1.3.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.4.0 which is incompatible.\n",
            "cvxpy 1.2.3 requires setuptools<=64.0.2, but you have setuptools 67.2.0 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.20.0 which is incompatible.\n",
            "aeppl 0.0.33 requires scipy>=1.4.0, but you have scipy 1.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.30 PyYAML-5.4 argunparse-0.1.2 boto3-1.26.68 botocore-1.29.68 configparser-5.3.0 docker-pycreds-0.4.0 gensim-3.8.0 gitdb-4.0.10 h5py-2.9.0 jmespath-1.0.1 joblib-0.14.0 librosa-0.7.0 matplotlib-3.1.2 nltk-3.4.5 numpy-1.20.0 pathtools-0.1.2 prettytable-0.7.2 pytorch_pretrained_bert-0.6.2 s3transfer-0.6.0 sacremoses-0.0.53 scikit_learn-0.23.2 scipy-1.3.2 semver-2.13.0 sentencepiece-0.1.97 sentry-sdk-1.15.0 setuptools-67.2.0 shortuuid-1.0.11 smmap-5.0.0 subprocess32-3.5.4 tokenizers-0.5.2 torch-1.4.0 tqdm-4.48.2 transformers-2.5.1 urllib3-1.26.14 version-query-1.2.0 wandb-0.10.15 watchdog-0.10.4 webrtcvad-2.0.10\n"
          ]
        }
      ],
      "source": [
        "%cd /content/mix-stage\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq6dKiTzmPJm",
        "outputId": "599b3720-ce40-4e5e-c8a3-3f12f49b7eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mix-stage/src\n",
            "--2023-02-07 13:24:00--  https://cmu.box.com/shared/static/gw9i4qvj2vykcq3krkkvq6nickb4chem.zip\n",
            "Resolving cmu.box.com (cmu.box.com)... 74.112.186.144\n",
            "Connecting to cmu.box.com (cmu.box.com)|74.112.186.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/gw9i4qvj2vykcq3krkkvq6nickb4chem.zip [following]\n",
            "--2023-02-07 13:24:01--  https://cmu.box.com/public/static/gw9i4qvj2vykcq3krkkvq6nickb4chem.zip\n",
            "Reusing existing connection to cmu.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cmu.app.box.com/public/static/gw9i4qvj2vykcq3krkkvq6nickb4chem.zip [following]\n",
            "--2023-02-07 13:24:01--  https://cmu.app.box.com/public/static/gw9i4qvj2vykcq3krkkvq6nickb4chem.zip\n",
            "Resolving cmu.app.box.com (cmu.app.box.com)... 74.112.186.144\n",
            "Connecting to cmu.app.box.com (cmu.app.box.com)|74.112.186.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl2.boxcloud.com/d/1/b1!aN5NC_duqkD91J_j1X7w4eOVnQ9bGdOg3xmizJpAhT2c85T67OhadmYwiTXuTNClQTap2ruqXe4_M7DVTNke9G-NZUyUowLap5mK1RoWEsMgwsyB_gaMWR6V5kbj7HbKOyc8etTZuB96PMC30sPBuTZov_qO_Ri0jNkCFXcKRI_7f5tUjlP-eM2Otd7MsuKr3SIwK1bzx588hLPSEyLvJFlj-0EVwRfjdpUj0yPb53gDnHfvGczHzdiUiM_Xdb_qlXlSM9FeJjxEvy5CHuJsWo6tPDqabgW5v7-wc1T1n9S9VxY9sqXUsViu5LBO9jdktSlTfxGtd1ZKYUV-SEnmLWU3olDNs2_NVkgTExqSmhQYaVxxVvpCkwYOzGsHOlTMCbo6BXukNlRbgb0G5UEetUMI67ZEzBCPuvzSsX3nkVDKnn2xKypQOlCl1O4CvV1trYniHtYAHgMMkdZUF5igkdHj1rJSgC2ZMuPPPIzkxg0ETK7BRvvlo_Tsx8qVN7wizuKxQnPPzxy1lUTLCmLYl2slJAmAzRmPuQ11r61arKuFgtt6vqk6a_BSh2QvoA47HU_5qYm27Fi24viiP1gYYULVhgDdBFwftI2CLfVXFqh15RFVXiuSvsPOMr1uTcRrA3IyhnNoR75Cus9SWwwthNABLHrZKbw8sykrDGYC3AvZthQfJyHJBUuY061XXSwzu5bjOTIH-o237V0yl7g6U9YRkeQd4qkAU8cRJCb3iwzxtV7O869znzsiJktDq0fG8_29U7YO73mU4p9wweC_xIC2DYqWbT_8Fi_nwIrKM764eFTo5occZvxk866vaypqe_EA5ga54voFkT4lX5gxC4gr4fYHMJyuv33tDeNwkeDR1U9F13oaqYv2ezr3QrjhGFn-6QeB3kw2RctrvUSsqeyCi1WhYSrsLB_ihEncpyxyN8S3q5-frui6o6HNjNjWK6d5sCgCTGysjrl9zqMxEHgf_nJmbn904AP_i4_DW1jjy9X3ebDtcahGWNJWqMd7qsWUiij-2eA6r2DGiQ-mBRS2SYFwS613bIPkMTHM29q8UDKWt9tizAu8frPAGJTKixD3YwwtV8UxHjDY8ryp2pKL6iocd6ItjrJCjrwO6ApR9ByAekIURRqaSuE_3AO3rGmi7GJvVM6On0UvPnQvT00E-SM6NsVjTJSKPRcBQb4wj0xIcIqnO8RUbF_MoLVxwwWKcwd1XNdsDHijJOZuGooZpAPnGV2Rnv-uCoQ7zexUz3hFCOHcZFQYwYXzH4TCyT69nr7dhHgZR18YP4ZR4C5R2BUfBAPOsPbMMfErYkU2d4AzcLrrXHkgDCdu8JfoSVCosfVYBwCC6Fq7e-blU_-IiCX9GC1n0mR74DufODrq67FbnKLofKP-2hWaq3QYhdYeNpLtEAh3OxiogC5BGqXbiCRGVWomaVVmFtguSB0JaReX/download [following]\n",
            "--2023-02-07 13:24:02--  https://dl2.boxcloud.com/d/1/b1!aN5NC_duqkD91J_j1X7w4eOVnQ9bGdOg3xmizJpAhT2c85T67OhadmYwiTXuTNClQTap2ruqXe4_M7DVTNke9G-NZUyUowLap5mK1RoWEsMgwsyB_gaMWR6V5kbj7HbKOyc8etTZuB96PMC30sPBuTZov_qO_Ri0jNkCFXcKRI_7f5tUjlP-eM2Otd7MsuKr3SIwK1bzx588hLPSEyLvJFlj-0EVwRfjdpUj0yPb53gDnHfvGczHzdiUiM_Xdb_qlXlSM9FeJjxEvy5CHuJsWo6tPDqabgW5v7-wc1T1n9S9VxY9sqXUsViu5LBO9jdktSlTfxGtd1ZKYUV-SEnmLWU3olDNs2_NVkgTExqSmhQYaVxxVvpCkwYOzGsHOlTMCbo6BXukNlRbgb0G5UEetUMI67ZEzBCPuvzSsX3nkVDKnn2xKypQOlCl1O4CvV1trYniHtYAHgMMkdZUF5igkdHj1rJSgC2ZMuPPPIzkxg0ETK7BRvvlo_Tsx8qVN7wizuKxQnPPzxy1lUTLCmLYl2slJAmAzRmPuQ11r61arKuFgtt6vqk6a_BSh2QvoA47HU_5qYm27Fi24viiP1gYYULVhgDdBFwftI2CLfVXFqh15RFVXiuSvsPOMr1uTcRrA3IyhnNoR75Cus9SWwwthNABLHrZKbw8sykrDGYC3AvZthQfJyHJBUuY061XXSwzu5bjOTIH-o237V0yl7g6U9YRkeQd4qkAU8cRJCb3iwzxtV7O869znzsiJktDq0fG8_29U7YO73mU4p9wweC_xIC2DYqWbT_8Fi_nwIrKM764eFTo5occZvxk866vaypqe_EA5ga54voFkT4lX5gxC4gr4fYHMJyuv33tDeNwkeDR1U9F13oaqYv2ezr3QrjhGFn-6QeB3kw2RctrvUSsqeyCi1WhYSrsLB_ihEncpyxyN8S3q5-frui6o6HNjNjWK6d5sCgCTGysjrl9zqMxEHgf_nJmbn904AP_i4_DW1jjy9X3ebDtcahGWNJWqMd7qsWUiij-2eA6r2DGiQ-mBRS2SYFwS613bIPkMTHM29q8UDKWt9tizAu8frPAGJTKixD3YwwtV8UxHjDY8ryp2pKL6iocd6ItjrJCjrwO6ApR9ByAekIURRqaSuE_3AO3rGmi7GJvVM6On0UvPnQvT00E-SM6NsVjTJSKPRcBQb4wj0xIcIqnO8RUbF_MoLVxwwWKcwd1XNdsDHijJOZuGooZpAPnGV2Rnv-uCoQ7zexUz3hFCOHcZFQYwYXzH4TCyT69nr7dhHgZR18YP4ZR4C5R2BUfBAPOsPbMMfErYkU2d4AzcLrrXHkgDCdu8JfoSVCosfVYBwCC6Fq7e-blU_-IiCX9GC1n0mR74DufODrq67FbnKLofKP-2hWaq3QYhdYeNpLtEAh3OxiogC5BGqXbiCRGVWomaVVmFtguSB0JaReX/download\n",
            "Resolving dl2.boxcloud.com (dl2.boxcloud.com)... 74.112.186.128\n",
            "Connecting to dl2.boxcloud.com (dl2.boxcloud.com)|74.112.186.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1143633496 (1.1G) [application/zip]\n",
            "Saving to: ‘/content/drive/MyDrive/mixstage_pretrained.zip’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]   1.06G  12.8MB/s    in 88s     \n",
            "\n",
            "2023-02-07 13:25:31 (12.4 MB/s) - ‘/content/drive/MyDrive/mixstage_pretrained.zip’ saved [1143633496/1143633496]\n",
            "\n",
            "unzip:  cannot find or open pretrained.zip, pretrained.zip.zip or pretrained.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/mix-stage/src\n",
        "!wget -O /content/drive/MyDrive/mixstage_pretrained.zip https://cmu.box.com/shared/static/gw9i4qvj2vykcq3krkkvq6nickb4chem.zip\n",
        "!unzip pretrained.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5UVzXD8yhxq",
        "outputId": "b502cd05-d2ba-4a43-c8ef-a3346fff3759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mix-stage/src\n"
          ]
        }
      ],
      "source": [
        "%cd /content/mix-stage/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHJoJUV7fVp2",
        "outputId": "94e9bb88-2a5c-4607-9a87-ff7c6dd21f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/mixstage_pretrained.zip\n",
            "  inflating: eccv2020-results.ipynb  \n",
            "   creating: save/pretrained_models/\n",
            "   creating: save/pretrained_models/multi-speaker/\n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_log.log  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_name.name  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_histogram.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_metrics.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_name.name  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_histogram.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_res.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_name.name  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_style.pkl  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_args.args  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_histogram.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_style.pkl  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_log.log  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_args.args  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_metrics.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_cummMetrics.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_res.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_metrics.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_log.log  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3659_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_cummMetrics.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_cummMetrics.json  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_style.pkl  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_args.args  \n",
            "  inflating: save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_res.json  \n",
            "   creating: save/pretrained_models/attribute/\n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_metrics.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_histogram.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_histogram.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_res.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_style.pkl  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_args.args  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_name.name  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_metrics.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_cummMetrics.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_style.pkl  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_args.args  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_res.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_name.name  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p  \n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_res.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_histogram.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_style.pkl  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_args.args  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_cummMetrics.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_res.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_log.log  \n",
            "  inflating: save/pretrained_models/attribute/exp_3675_cpk_s2g_gst_eviltwin15_speaker_['lec_cosmic|leftarm', 'lec_cosmic|rightarm']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_log.log  \n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_metrics.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_style.pkl  \n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_args.args  \n",
            "  inflating: save/pretrained_models/attribute/exp_3674_cpk_s2g_gst_eviltwin15_speaker_['chemistry', 'lec_evol']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_name.name  \n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_cummMetrics.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_metrics.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_cummMetrics.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_log.log  \n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_histogram.json  \n",
            "  inflating: save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_name.name  \n",
            "  inflating: save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_log.log  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/mixstage_pretrained.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat > /usr/local/lib/python3.8/dist-packages/librosa/util/decorators.py << EOL\n",
        "#!/usr/bin/env python\n",
        "# -*- encoding: utf-8 -*-\n",
        "# CREATED:2015-02-15 10:06:03 by Brian McFee <brian.mcfee@nyu.edu>\n",
        "'''Helpful tools for deprecation'''\n",
        "\n",
        "import warnings\n",
        "from decorator import decorator\n",
        "import six\n",
        "#from numba.decorators import jit as optional_jit\n",
        "\n",
        "__all__ = ['moved', 'deprecated']\n",
        "\n",
        "\n",
        "def moved(moved_from, version, version_removed):\n",
        "    '''This is a decorator which can be used to mark functions\n",
        "    as moved/renamed.\n",
        "\n",
        "    It will result in a warning being emitted when the function is used.\n",
        "    '''\n",
        "\n",
        "    def __wrapper(func, *args, **kwargs):\n",
        "        '''Warn the user, and then proceed.'''\n",
        "        code = six.get_function_code(func)\n",
        "        warnings.warn_explicit(\n",
        "            \"{:s}\\n\\tThis function was moved to '{:s}.{:s}' in \"\n",
        "            \"librosa version {:s}.\"\n",
        "            \"\\n\\tThis alias will be removed in librosa version \"\n",
        "            \"{:s}.\".format(moved_from, func.__module__,\n",
        "                           func.__name__, version, version_removed),\n",
        "\n",
        "            category=DeprecationWarning,\n",
        "            filename=code.co_filename,\n",
        "            lineno=code.co_firstlineno + 1\n",
        "        )\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return decorator(__wrapper)\n",
        "\n",
        "\n",
        "def deprecated(version, version_removed):\n",
        "    '''This is a decorator which can be used to mark functions\n",
        "    as deprecated.\n",
        "\n",
        "    It will result in a warning being emitted when the function is used.'''\n",
        "\n",
        "    def __wrapper(func, *args, **kwargs):\n",
        "        '''Warn the user, and then proceed.'''\n",
        "        code = six.get_function_code(func)\n",
        "        warnings.warn_explicit(\n",
        "            \"{:s}.{:s}\\n\\tDeprecated as of librosa version {:s}.\"\n",
        "            \"\\n\\tIt will be removed in librosa version {:s}.\"\n",
        "            .format(func.__module__, func.__name__,\n",
        "                    version, version_removed),\n",
        "            category=DeprecationWarning,\n",
        "            filename=code.co_filename,\n",
        "            lineno=code.co_firstlineno + 1\n",
        "        )\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return decorator(__wrapper)\n",
        "EOL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "LCtoFr_cDOUT",
        "outputId": "dd3a5365-1ba8-4489-aef7-3c457da6b31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: warning: here-document at line 0 delimited by end-of-file (wanted `EOL')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f4de1c9536c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mEOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'EOL' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python render.py -render 20 -load /content/mix-stage/src/save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_\\[\\'corden\\',\\ \\'lec_cosmic\\',\\ \\'ytch_prof\\',\\ \\'oliver\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p -render_text 0 -path2data ../data -save_dir ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOz_WGPODSss",
        "outputId": "632f47c0-53a9-4f7c-e461-150e293a792b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"/content/mix-stage/src/save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[20], render_list=[None], render_text=[0], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['../'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "Namespace(angles=[90], batch_size=32, clean_render=1, config=None, cpk='m', cpu=10, cuda=0, curriculum=0, debug=0, dev_key='dev', dev_sign=1, dg_iter_ratio=1, discriminator=None, early_stopping=1, eps=0, exp=None, feats=['pose', 'velocity'], filler=0, finetune_quantile_sample=None, fs_new=[15, 15], gamma=0.99, gan=0, greedy_save=1, input_modalities=None, joint=0, kl_anneal=0, lambda_D=1, lambda_gan=1, load=\"/content/mix-stage/src/save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\", load_data=1, loss='MSELoss', lossKwargs={}, lr=0.0001, mask=[0, 7, 8, 9], mem=16000, metrics=1, min_epochs=0, mix=0, modalities=['pose/data', 'audio/log_mel_512'], model='SnL2PoseLate_G', modelKwargs={}, no_grad=0, noise=0, noise_only=0, note=None, num_clusters=None, num_epochs=50, num_iters=0, num_training_iters=None, num_training_sample=None, num_workers=1, optim='Adam', optimKwargs={}, optim_separate=None, output_modalities=None, overfit=0, path2data='../data', path2outdata='../dataset/groot/data', pos=0, preprocess_methods=['log_mel_512'], preprocess_only=0, prequel='source activate torch\\\\n', pretrained_model=0, pretrained_model_weights=None, quantile_num_training_sample=3000, quantile_sample=None, relative2parent=0, render=20, render_list=None, render_text=0, render_transparent=0, repeat_text=1, sample_all_styles=0, save_dir='../', save_model=1, scheduler=None, scheduler_warmup_steps=0, script=None, seed=11212, shuffle=1, speaker='oliver', split=None, stop_thresh=3, style_dim=10, style_iters=0, style_losses={'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}, tb=0, text_aligned=1, time=4.3, transforms=['mirror'], update_D_prob_flag=0, view='sentences.txt', weighted=0, window_hop=0)\n",
            "Results Loaded\n",
            "100% 10/10 [00:00<00:00, 118.24it/s]\n",
            "100% 10/10 [00:00<00:00, 118.39it/s]\n",
            "100% 10/10 [00:00<00:00, 115.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzQ7aJm4hhlN"
      },
      "outputs": [],
      "source": [
        "!python sample.py \\\n",
        "-load save/pretrained_models/aisle/lec_cosmic/exp_3233_cpk_mmsbert_lfiw_no_update3_speaker_\\[\\'oliver\\'\\]_model_JointLateClusterSoftTransformer12_G_note_mmsbert_lfiw_no_update3_weights.p \\\n",
        "-path2data ../data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk-b5vDef88z",
        "outputId": "17df3ee2-91aa-4c02-cfc4-46b8af560ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[0], render_list=[None], render_text=[1], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['save/model'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "Namespace(angles=[90], batch_size=32, clean_render=1, config=None, cpk='m', cpu=10, cuda=0, curriculum=0, debug=0, dev_key='dev', dev_sign=1, dg_iter_ratio=1, discriminator=None, early_stopping=1, eps=0, exp=None, feats=['pose', 'velocity'], filler=0, finetune_quantile_sample=None, fs_new=[15, 15], gamma=0.99, gan=0, greedy_save=1, input_modalities=None, joint=0, kl_anneal=0, lambda_D=1, lambda_gan=1, load=\"save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\", load_data=1, loss='MSELoss', lossKwargs={}, lr=0.0001, mask=[0, 7, 8, 9], mem=16000, metrics=1, min_epochs=0, mix=0, modalities=['pose/data', 'audio/log_mel_512'], model='SnL2PoseLate_G', modelKwargs={}, no_grad=0, noise=0, noise_only=0, note=None, num_clusters=None, num_epochs=50, num_iters=0, num_training_iters=None, num_training_sample=None, num_workers=1, optim='Adam', optimKwargs={}, optim_separate=None, output_modalities=None, overfit=0, path2data='../data', path2outdata='../dataset/groot/data', pos=0, preprocess_methods=['log_mel_512'], preprocess_only=0, prequel='source activate torch\\\\n', pretrained_model=0, pretrained_model_weights=None, quantile_num_training_sample=3000, quantile_sample=None, relative2parent=0, render=0, render_list=None, render_text=1, render_transparent=0, repeat_text=1, sample_all_styles=0, save_dir='save/model', save_model=1, scheduler=None, scheduler_warmup_steps=0, script=None, seed=11212, shuffle=1, speaker='oliver', split=None, stop_thresh=3, style_dim=10, style_iters=0, style_losses={'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}, tb=0, text_aligned=1, time=4.3, transforms=['mirror'], update_D_prob_flag=0, view='sentences.txt', weighted=0, window_hop=0)\n",
            "Results Loaded\n",
            "model.trainer.TrainerJointLateClusterStyleGAN selected\n",
            "Results Loaded\n",
            "100% 15839/15839 [5:58:09<00:00,  1.36s/it]\n",
            "100% 1798/1798 [39:49<00:00,  1.33s/it]\n",
            "100% 2117/2117 [46:30<00:00,  1.32s/it]\n",
            "Data Loaded\n",
            "Loading KMeans model for ['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']/centers/8_pose_velocity_speed_0_7_8_9_pose_normalize\n",
            "Model Created\n",
            "Loading Model\n",
            "Loading Mean-Variance for pose/normalize\n",
            "Loading Mean-Variance for audio/log_mel_400\n",
            "Loading KMeans model for ['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']/centers/8_pose_velocity_speed_0_7_8_9_pose_normalize\n",
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[0], render_list=[None], render_text=[1], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['save/model'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "/content/mix-stage/src/pycasper/BookKeeper.py:224: UserWarning: Counld not find results file\n",
            "  warnings.warn('Counld not find results file')\n",
            "model.trainer.TrainerStyleClassifier selected\n",
            "100% 10/10 [01:57<00:00, 11.75s/it]\n",
            "100% 10/10 [00:20<00:00,  2.00s/it]\n",
            "100% 10/10 [00:16<00:00,  1.64s/it]\n",
            "Data Loaded\n",
            "Loading KMeans model for ['all']/centers/8_pose_velocity_0_7_8_9_pose_normalize\n",
            "Model Created\n",
            "Loading Model\n",
            "Loading Mean-Variance for pose/normalize\n",
            "Loading KMeans model for ['all']/centers/8_pose_velocity_0_7_8_9_pose_normalize\n",
            "  0%[00:00<?]:test pose:0.000 G_gan:0.000 real_D:0.000 fake_D:0.000 label:0.000 id_in:0.000 id_out:0.000 H:0.000/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n",
            "/content/mix-stage/src/evaluation/metrics.py:146: RuntimeWarning: invalid value encountered in true_divide\n",
            "  precision = np.diag(self.cm)/np.sum(self.cm, axis=0)\n",
            "/content/mix-stage/src/evaluation/metrics.py:157: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f1 = 2*(precision*recall/(precision + recall))\n",
            "/content/mix-stage/src/evaluation/metrics.py:150: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = np.diag(self.cm)/np.sum(self.cm, axis=1)\n",
            "Sampled- Train:0.8259/0.3166, Dev:0.8514/0.3440, Test:0.8621/0.3418\n",
            "exp: 0, epch: 0, lr:0\n",
            "+----------+--------+--------+--------+\n",
            "|          | train  |  dev   |  test  |\n",
            "+----------+--------+--------+--------+\n",
            "|   loss   | 0.6386 | 0.6852 | 0.7133 |\n",
            "|   pck    | 0.4764 | 0.4087 | 0.3993 |\n",
            "|    F1    | 0.5325 | 0.3363 | 0.3306 |\n",
            "| style_IS | 4.2364 | 4.5869 | 4.4770 |\n",
            "+----------+--------+--------+--------+\n",
            "3663\n"
          ]
        }
      ],
      "source": [
        "!python sample.py \\\n",
        "-load save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_\\[\\'corden\\',\\ \\'lec_cosmic\\',\\ \\'ytch_prof\\',\\ \\'oliver\\',\\ \\'ellen\\',\\ \\'noah\\',\\ \\'lec_evol\\',\\ \\'maher\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p   \\\n",
        "-path2data ../data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p6mep8mGJNI",
        "outputId": "2c7406cf-5fbf-4d20-9734-ad37541f34cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[0], render_list=[None], render_text=[1], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['save/model'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "Namespace(angles=[90], batch_size=32, clean_render=1, config=None, cpk='m', cpu=10, cuda=0, curriculum=0, debug=0, dev_key='dev', dev_sign=1, dg_iter_ratio=1, discriminator=None, early_stopping=1, eps=0, exp=None, feats=['pose', 'velocity'], filler=0, finetune_quantile_sample=None, fs_new=[15, 15], gamma=0.99, gan=0, greedy_save=1, input_modalities=None, joint=0, kl_anneal=0, lambda_D=1, lambda_gan=1, load=\"save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\", load_data=1, loss='MSELoss', lossKwargs={}, lr=0.0001, mask=[0, 7, 8, 9], mem=16000, metrics=1, min_epochs=0, mix=0, modalities=['pose/data', 'audio/log_mel_512'], model='SnL2PoseLate_G', modelKwargs={}, no_grad=0, noise=0, noise_only=0, note=None, num_clusters=None, num_epochs=50, num_iters=0, num_training_iters=None, num_training_sample=None, num_workers=1, optim='Adam', optimKwargs={}, optim_separate=None, output_modalities=None, overfit=0, path2data='../data', path2outdata='../dataset/groot/data', pos=0, preprocess_methods=['log_mel_512'], preprocess_only=0, prequel='source activate torch\\\\n', pretrained_model=0, pretrained_model_weights=None, quantile_num_training_sample=3000, quantile_sample=None, relative2parent=0, render=0, render_list=None, render_text=1, render_transparent=0, repeat_text=1, sample_all_styles=0, save_dir='save/model', save_model=1, scheduler=None, scheduler_warmup_steps=0, script=None, seed=11212, shuffle=1, speaker='oliver', split=None, stop_thresh=3, style_dim=10, style_iters=0, style_losses={'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}, tb=0, text_aligned=1, time=4.3, transforms=['mirror'], update_D_prob_flag=0, view='sentences.txt', weighted=0, window_hop=0)\n",
            "Results Loaded\n",
            "model.trainer.TrainerJointLateClusterStyleGAN selected\n",
            "Results Loaded\n",
            "100% 7106/7106 [2:25:33<00:00,  1.23s/it]\n",
            "100% 786/786 [16:13<00:00,  1.24s/it]\n",
            "100% 832/832 [16:25<00:00,  1.18s/it]\n",
            "Data Loaded\n",
            "Loading KMeans model for ['corden', 'lec_cosmic', 'ytch_prof', 'oliver']/centers/8_pose_velocity_speed_0_7_8_9_pose_normalize\n",
            "Model Created\n",
            "Loading Model\n",
            "Loading Mean-Variance for pose/normalize\n",
            "Loading Mean-Variance for audio/log_mel_400\n",
            "Loading KMeans model for ['corden', 'lec_cosmic', 'ytch_prof', 'oliver']/centers/8_pose_velocity_speed_0_7_8_9_pose_normalize\n",
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[0], render_list=[None], render_text=[1], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['save/model'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "/content/mix-stage/src/pycasper/BookKeeper.py:224: UserWarning: Counld not find results file\n",
            "  warnings.warn('Counld not find results file')\n",
            "model.trainer.TrainerStyleClassifier selected\n",
            "100% 10/10 [02:29<00:00, 14.92s/it]\n",
            "100% 10/10 [00:12<00:00,  1.22s/it]\n",
            "100% 10/10 [00:11<00:00,  1.14s/it]\n",
            "Data Loaded\n",
            "Loading KMeans model for ['all']/centers/8_pose_velocity_0_7_8_9_pose_normalize\n",
            "Model Created\n",
            "Loading Model\n",
            "Loading Mean-Variance for pose/normalize\n",
            "Loading KMeans model for ['all']/centers/8_pose_velocity_0_7_8_9_pose_normalize\n",
            "  0%[00:00<?]:test pose:0.000 G_gan:0.000 real_D:0.000 fake_D:0.000 label:0.000 id_in:0.000 id_out:0.000 H:0.000/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n",
            "/content/mix-stage/src/evaluation/metrics.py:146: RuntimeWarning: invalid value encountered in true_divide\n",
            "  precision = np.diag(self.cm)/np.sum(self.cm, axis=0)\n",
            "/content/mix-stage/src/evaluation/metrics.py:150: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = np.diag(self.cm)/np.sum(self.cm, axis=1)\n",
            "/content/mix-stage/src/evaluation/metrics.py:157: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f1 = 2*(precision*recall/(precision + recall))\n",
            " 60%[1:52:19<58:59]:train pose:0.827 G_gan:0.000 real_D:0.000 fake_D:0.000 label:0.000 id_in:0.000 id_out:0.000 H:0.000: "
          ]
        }
      ],
      "source": [
        "!python sample.py \\\n",
        "-load save/pretrained_models/multi-speaker/exp_3661_cpk_JointLateClusterSoftStyle4_G_speaker_\\[\\'corden\\',\\ \\'lec_cosmic\\',\\ \\'ytch_prof\\',\\ \\'oliver\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p \\\n",
        "-path2data ../data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRXGysF_LBqs",
        "outputId": "2a3c0b55-45c4-4532-aa0b-4a017f6bc69d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[0], render_list=[None], render_text=[1], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['save/model'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "Namespace(angles=[90], batch_size=32, clean_render=1, config=None, cpk='m', cpu=10, cuda=0, curriculum=0, debug=0, dev_key='dev', dev_sign=1, dg_iter_ratio=1, discriminator=None, early_stopping=1, eps=0, exp=None, feats=['pose', 'velocity'], filler=0, finetune_quantile_sample=None, fs_new=[15, 15], gamma=0.99, gan=0, greedy_save=1, input_modalities=None, joint=0, kl_anneal=0, lambda_D=1, lambda_gan=1, load=\"save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p\", load_data=1, loss='MSELoss', lossKwargs={}, lr=0.0001, mask=[0, 7, 8, 9], mem=16000, metrics=1, min_epochs=0, mix=0, modalities=['pose/data', 'audio/log_mel_512'], model='SnL2PoseLate_G', modelKwargs={}, no_grad=0, noise=0, noise_only=0, note=None, num_clusters=None, num_epochs=50, num_iters=0, num_training_iters=None, num_training_sample=None, num_workers=1, optim='Adam', optimKwargs={}, optim_separate=None, output_modalities=None, overfit=0, path2data='../data', path2outdata='../dataset/groot/data', pos=0, preprocess_methods=['log_mel_512'], preprocess_only=0, prequel='source activate torch\\\\n', pretrained_model=0, pretrained_model_weights=None, quantile_num_training_sample=3000, quantile_sample=None, relative2parent=0, render=0, render_list=None, render_text=1, render_transparent=0, repeat_text=1, sample_all_styles=0, save_dir='save/model', save_model=1, scheduler=None, scheduler_warmup_steps=0, script=None, seed=11212, shuffle=1, speaker='oliver', split=None, stop_thresh=3, style_dim=10, style_iters=0, style_losses={'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}, tb=0, text_aligned=1, time=4.3, transforms=['mirror'], update_D_prob_flag=0, view='sentences.txt', weighted=0, window_hop=0)\n",
            "Results Loaded\n",
            "model.trainer.TrainerJointLateClusterStyleGAN selected\n",
            "Results Loaded\n",
            "100% 4490/4490 [27:07<00:00,  2.76it/s]\n",
            "100% 493/493 [02:52<00:00,  2.86it/s]\n",
            "100% 546/546 [03:14<00:00,  2.81it/s]\n",
            "Data Loaded\n",
            "Loading KMeans model for ['seth', 'oliver']/centers/8_pose_velocity_speed_0_7_8_9_pose_normalize\n",
            "Model Created\n",
            "Loading Model\n",
            "Loading Mean-Variance for pose/normalize\n",
            "Loading Mean-Variance for audio/log_mel_400\n",
            "Loading KMeans model for ['seth', 'oliver']/centers/8_pose_velocity_speed_0_7_8_9_pose_normalize\n",
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_['seth', 'oliver']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[0], render_list=[None], render_text=[1], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['save/model'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "/content/mix-stage/src/pycasper/BookKeeper.py:224: UserWarning: Counld not find results file\n",
            "  warnings.warn('Counld not find results file')\n",
            "model.trainer.TrainerStyleClassifier selected\n",
            "100% 10/10 [00:03<00:00,  2.90it/s]\n",
            "100% 10/10 [00:00<00:00, 61.72it/s]\n",
            "100% 10/10 [00:00<00:00, 18.70it/s]\n",
            "Data Loaded\n",
            "Loading KMeans model for ['all']/centers/8_pose_velocity_0_7_8_9_pose_normalize\n",
            "Model Created\n",
            "Loading Model\n",
            "Loading Mean-Variance for pose/normalize\n",
            "Loading KMeans model for ['all']/centers/8_pose_velocity_0_7_8_9_pose_normalize\n",
            "  0%[00:00<?]:test pose:0.000 G_gan:0.000 real_D:0.000 fake_D:0.000 label:0.000 id_in:0.000 id_out:0.000 H:0.000/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2970: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n",
            "/content/mix-stage/src/evaluation/metrics.py:157: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f1 = 2*(precision*recall/(precision + recall))\n",
            "/content/mix-stage/src/evaluation/metrics.py:146: RuntimeWarning: invalid value encountered in true_divide\n",
            "  precision = np.diag(self.cm)/np.sum(self.cm, axis=0)\n",
            "/content/mix-stage/src/evaluation/metrics.py:150: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = np.diag(self.cm)/np.sum(self.cm, axis=1)\n",
            "Sampled- Train:0.6907/0.5761, Dev:0.6736/0.5049, Test:0.7512/0.4787\n",
            "exp: 0, epch: 0, lr:0\n",
            "+----------+--------+--------+--------+\n",
            "|          | train  |  dev   |  test  |\n",
            "+----------+--------+--------+--------+\n",
            "|   loss   | 0.4787 | 0.5648 | 0.6050 |\n",
            "|   pck    | 0.6539 | 0.5884 | 0.5765 |\n",
            "|    F1    | 0.6950 | 0.5620 | 0.5274 |\n",
            "| style_IS | 4.1518 | 3.4213 | 4.4969 |\n",
            "+----------+--------+--------+--------+\n",
            "3669\n"
          ]
        }
      ],
      "source": [
        "!python sample.py \\\n",
        "-load save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_\\[\\'seth\\',\\ \\'oliver\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p \\\n",
        "-path2data ../data \\\n",
        "-path2outdata ../dataset/groot/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP5eduaLiJyF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLJ3RF6Oqzh5",
        "outputId": "ebbf0d1c-476c-4d67-a826-f47643312517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[20], render_list=[None], render_text=[1], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['save/model'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "Namespace(angles=[90], batch_size=32, clean_render=1, config=None, cpk='m', cpu=10, cuda=0, curriculum=0, debug=0, dev_key='dev', dev_sign=1, dg_iter_ratio=1, discriminator=None, early_stopping=1, eps=0, exp=None, feats=['pose', 'velocity'], filler=0, finetune_quantile_sample=None, fs_new=[15, 15], gamma=0.99, gan=0, greedy_save=1, input_modalities=None, joint=0, kl_anneal=0, lambda_D=1, lambda_gan=1, load=\"save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_['noah', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p\", load_data=1, loss='MSELoss', lossKwargs={}, lr=0.0001, mask=[0, 7, 8, 9], mem=16000, metrics=1, min_epochs=0, mix=0, modalities=['pose/data', 'audio/log_mel_512'], model='SnL2PoseLate_G', modelKwargs={}, no_grad=0, noise=0, noise_only=0, note=None, num_clusters=None, num_epochs=50, num_iters=0, num_training_iters=None, num_training_sample=None, num_workers=1, optim='Adam', optimKwargs={}, optim_separate=None, output_modalities=None, overfit=0, path2data='../data', path2outdata='../dataset/groot/data', pos=0, preprocess_methods=['log_mel_512'], preprocess_only=0, prequel='source activate torch\\\\n', pretrained_model=0, pretrained_model_weights=None, quantile_num_training_sample=3000, quantile_sample=None, relative2parent=0, render=20, render_list=None, render_text=1, render_transparent=0, repeat_text=1, sample_all_styles=0, save_dir='save/model', save_model=1, scheduler=None, scheduler_warmup_steps=0, script=None, seed=11212, shuffle=1, speaker='oliver', split=None, stop_thresh=3, style_dim=10, style_iters=0, style_losses={'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}, tb=0, text_aligned=1, time=4.3, transforms=['mirror'], update_D_prob_flag=0, view='sentences.txt', weighted=0, window_hop=0)\n",
            "Results Loaded\n",
            "100% 10/10 [00:00<00:00, 123.13it/s]\n",
            "100% 10/10 [00:00<00:00, 132.27it/s]\n",
            "100% 10/10 [00:00<00:00, 115.33it/s]\n"
          ]
        }
      ],
      "source": [
        "!python render.py -render 20 -load save/pretrained_models/attribute/exp_3668_cpk_s2g_gst_eviltwin15_speaker_\\[\\'noah\\',\\ \\'maher\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p -render_text 1 -path2data ../data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDq1z9p1Bw_J",
        "outputId": "41e7562d-678e-44fe-fc0f-e678e59f397f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(angles=[[90]], batch_size=[32], clean_render=[1], config=[None], cpk=['m'], cpu=[10], cuda=[0], curriculum=[0], debug=[0], dev_key=['dev'], dev_sign=[1], dg_iter_ratio=[1], discriminator=[None], early_stopping=[1], eps=[0], exp=[None], feats=[['pose', 'velocity']], filler=[0], finetune_quantile_sample=[None], fs_new=[[15, 15]], gamma=[0.99], gan=[0], greedy_save=[1], input_modalities=[None], joint=[0], kl_anneal=[0], lambda_D=[1], lambda_gan=[1], load=[\"/content/mix-stage/src/save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\"], load_data=[1], loss=['MSELoss'], lossKwargs=[{}], lr=[0.0001], mask=[[0, 7, 8, 9]], mem=[16000], metrics=[1], min_epochs=[0], mix=[0], modalities=[['pose/data', 'audio/log_mel_512']], model=['SnL2PoseLate_G'], modelKwargs=[{}], no_grad=[0], noise=[0], noise_only=[0], note=[None], num_clusters=[None], num_epochs=[50], num_iters=[0], num_training_iters=[None], num_training_sample=[None], num_workers=[1], optim=['Adam'], optimKwargs=[{}], optim_separate=[None], output_modalities=[None], overfit=[0], path2data=['../data'], path2outdata=['../dataset/groot/data'], pos=[0], preprocess_methods=[['log_mel_512']], preprocess_only=[0], prequel=['source activate torch\\\\n'], pretrained_model=[0], pretrained_model_weights=[None], quantile_num_training_sample=[3000], quantile_sample=[None], relative2parent=[0], render=[0], render_list=[None], render_text=[1], render_transparent=[0], repeat_text=[1], sample_all_styles=[0], save_dir=['save/model'], save_model=[1], scheduler=[None], scheduler_warmup_steps=[0], script=[None], seed=[11212], shuffle=[1], speaker=['oliver'], split=[None], stop_thresh=[3], style_dim=[10], style_iters=[0], style_losses=[{'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}], tb=[0], text_aligned=[1], time=[4.3], transforms=[['mirror']], update_D_prob_flag=[0], view=['sentences.txt'], weighted=[0], window_hop=[0])\n",
            "[]\n",
            "Namespace(angles=[90], batch_size=32, clean_render=1, config=None, cpk='m', cpu=10, cuda=0, curriculum=0, debug=0, dev_key='dev', dev_sign=1, dg_iter_ratio=1, discriminator=None, early_stopping=1, eps=0, exp=None, feats=['pose', 'velocity'], filler=0, finetune_quantile_sample=None, fs_new=[15, 15], gamma=0.99, gan=0, greedy_save=1, input_modalities=None, joint=0, kl_anneal=0, lambda_D=1, lambda_gan=1, load=\"/content/mix-stage/src/save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_['corden', 'lec_cosmic', 'ytch_prof', 'oliver', 'ellen', 'noah', 'lec_evol', 'maher']_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p\", load_data=1, loss='MSELoss', lossKwargs={}, lr=0.0001, mask=[0, 7, 8, 9], mem=16000, metrics=1, min_epochs=0, mix=0, modalities=['pose/data', 'audio/log_mel_512'], model='SnL2PoseLate_G', modelKwargs={}, no_grad=0, noise=0, noise_only=0, note=None, num_clusters=None, num_epochs=50, num_iters=0, num_training_iters=None, num_training_sample=None, num_workers=1, optim='Adam', optimKwargs={}, optim_separate=None, output_modalities=None, overfit=0, path2data='../data', path2outdata='../dataset/groot/data', pos=0, preprocess_methods=['log_mel_512'], preprocess_only=0, prequel='source activate torch\\\\n', pretrained_model=0, pretrained_model_weights=None, quantile_num_training_sample=3000, quantile_sample=None, relative2parent=0, render=0, render_list=None, render_text=1, render_transparent=0, repeat_text=1, sample_all_styles=0, save_dir='save/model', save_model=1, scheduler=None, scheduler_warmup_steps=0, script=None, seed=11212, shuffle=1, speaker='oliver', split=None, stop_thresh=3, style_dim=10, style_iters=0, style_losses={'id_a': 1, 'id_p': 1, 'cluster_a': 1, 'cluster_p': 1, 'style_a': 1, 'style_p': 1, 'content_+': 1, 'content_-': 1, 'rec_a': 1, 'rec_p': 1}, tb=0, text_aligned=1, time=4.3, transforms=['mirror'], update_D_prob_flag=0, view='sentences.txt', weighted=0, window_hop=0)\n",
            "Results Loaded\n",
            "model.trainer.TrainerJointLateClusterStyleGAN selected\n",
            "Results Loaded\n",
            " 83% 13076/15839 [3:16:19<1:05:25,  1.42s/it]^C\n"
          ]
        }
      ],
      "source": [
        "!python sample.py \\\n",
        "-load /content/mix-stage/src/save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_\\[\\'corden\\',\\ \\'lec_cosmic\\',\\ \\'ytch_prof\\',\\ \\'oliver\\',\\ \\'ellen\\',\\ \\'noah\\',\\ \\'lec_evol\\',\\ \\'maher\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15_weights.p \\\n",
        "-path2data ../data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-mfD-rrHcz3"
      },
      "outputs": [],
      "source": [
        "!python sample.py \\\n",
        "-load save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_\\[\\'seth\\',\\ \\'oliver\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p \\\n",
        "-path2data ../data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPf8IiiV-l18",
        "outputId": "305643dc-48f2-4c0e-e8c6-1e331f22b68a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: render.py\n",
            "       [-h]\n",
            "       [-path2data PATH2DATA [PATH2DATA ...]]\n",
            "       [-path2outdata PATH2OUTDATA [PATH2OUTDATA ...]]\n",
            "       [-speaker SPEAKER [SPEAKER ...]]\n",
            "       [-modalities MODALITIES [MODALITIES ...]]\n",
            "       [-input_modalities INPUT_MODALITIES [INPUT_MODALITIES ...]]\n",
            "       [-output_modalities OUTPUT_MODALITIES [OUTPUT_MODALITIES ...]]\n",
            "       [-mask MASK [MASK ...]]\n",
            "       [-split SPLIT [SPLIT ...]]\n",
            "       [-batch_size BATCH_SIZE [BATCH_SIZE ...]]\n",
            "       [-shuffle SHUFFLE [SHUFFLE ...]]\n",
            "       [-time TIME [TIME ...]]\n",
            "       [-fs_new FS_NEW [FS_NEW ...]]\n",
            "       [-num_workers NUM_WORKERS [NUM_WORKERS ...]]\n",
            "       [-window_hop WINDOW_HOP [WINDOW_HOP ...]]\n",
            "       [-num_clusters NUM_CLUSTERS [NUM_CLUSTERS ...]]\n",
            "       [-pos POS [POS ...]]\n",
            "       [-feats FEATS [FEATS ...]]\n",
            "       [-style_dim STYLE_DIM [STYLE_DIM ...]]\n",
            "       [-style_losses STYLE_LOSSES [STYLE_LOSSES ...]]\n",
            "       [-style_iters STYLE_ITERS [STYLE_ITERS ...]]\n",
            "       [-load_data LOAD_DATA [LOAD_DATA ...]]\n",
            "       [-repeat_text REPEAT_TEXT [REPEAT_TEXT ...]]\n",
            "       [-filler FILLER [FILLER ...]]\n",
            "       [-relative2parent RELATIVE2PARENT [RELATIVE2PARENT ...]]\n",
            "       [-quantile_sample QUANTILE_SAMPLE [QUANTILE_SAMPLE ...]]\n",
            "       [-quantile_num_training_sample QUANTILE_NUM_TRAINING_SAMPLE [QUANTILE_NUM_TRAINING_SAMPLE ...]]\n",
            "       [-finetune_quantile_sample FINETUNE_QUANTILE_SAMPLE [FINETUNE_QUANTILE_SAMPLE ...]]\n",
            "       [-pretrained_model PRETRAINED_MODEL [PRETRAINED_MODEL ...]]\n",
            "       [-pretrained_model_weights PRETRAINED_MODEL_WEIGHTS [PRETRAINED_MODEL_WEIGHTS ...]]\n",
            "       [-noise NOISE [NOISE ...]]\n",
            "       [-view VIEW [VIEW ...]]\n",
            "       [-exp EXP [EXP ...]]\n",
            "       [-debug DEBUG [DEBUG ...]]\n",
            "       [-save_dir SAVE_DIR [SAVE_DIR ...]]\n",
            "       [-cpk CPK [CPK ...]]\n",
            "       [-dev_key DEV_KEY [DEV_KEY ...]]\n",
            "       [-dev_sign DEV_SIGN [DEV_SIGN ...]]\n",
            "       [-tb TB [TB ...]]\n",
            "       [-seed SEED [SEED ...]]\n",
            "       [-load LOAD [LOAD ...]]\n",
            "       [-cuda CUDA [CUDA ...]]\n",
            "       [-overfit OVERFIT [OVERFIT ...]]\n",
            "       [-note NOTE [NOTE ...]]\n",
            "       [-model MODEL [MODEL ...]]\n",
            "       [-modelKwargs MODELKWARGS [MODELKWARGS ...]]\n",
            "       [-gan GAN [GAN ...]]\n",
            "       [-dg_iter_ratio DG_ITER_RATIO [DG_ITER_RATIO ...]]\n",
            "       [-lambda_gan LAMBDA_GAN [LAMBDA_GAN ...]]\n",
            "       [-lambda_D LAMBDA_D [LAMBDA_D ...]]\n",
            "       [-joint JOINT [JOINT ...]]\n",
            "       [-update_D_prob_flag UPDATE_D_PROB_FLAG [UPDATE_D_PROB_FLAG ...]]\n",
            "       [-no_grad NO_GRAD [NO_GRAD ...]]\n",
            "       [-discriminator DISCRIMINATOR [DISCRIMINATOR ...]]\n",
            "       [-weighted WEIGHTED [WEIGHTED ...]]\n",
            "       [-noise_only NOISE_ONLY [NOISE_ONLY ...]]\n",
            "       [-loss LOSS [LOSS ...]]\n",
            "       [-lossKwargs LOSSKWARGS [LOSSKWARGS ...]]\n",
            "       [-preprocess_methods PREPROCESS_METHODS [PREPROCESS_METHODS ...]]\n",
            "       [-preprocess_only PREPROCESS_ONLY [PREPROCESS_ONLY ...]]\n",
            "       [-text_aligned TEXT_ALIGNED [TEXT_ALIGNED ...]]\n",
            "       [-num_epochs NUM_EPOCHS [NUM_EPOCHS ...]]\n",
            "       [-early_stopping EARLY_STOPPING [EARLY_STOPPING ...]]\n",
            "       [-greedy_save GREEDY_SAVE [GREEDY_SAVE ...]]\n",
            "       [-save_model SAVE_MODEL [SAVE_MODEL ...]]\n",
            "       [-stop_thresh STOP_THRESH [STOP_THRESH ...]]\n",
            "       [-min_epochs MIN_EPOCHS [MIN_EPOCHS ...]]\n",
            "       [-eps EPS [EPS ...]]\n",
            "       [-num_iters NUM_ITERS [NUM_ITERS ...]]\n",
            "       [-num_training_iters NUM_TRAINING_ITERS [NUM_TRAINING_ITERS ...]]\n",
            "       [-num_training_sample NUM_TRAINING_SAMPLE [NUM_TRAINING_SAMPLE ...]]\n",
            "       [-metrics METRICS [METRICS ...]]\n",
            "       [-curriculum CURRICULUM [CURRICULUM ...]]\n",
            "       [-kl_anneal KL_ANNEAL [KL_ANNEAL ...]]\n",
            "       [-optim OPTIM [OPTIM ...]]\n",
            "       [-lr LR [LR ...]]\n",
            "       [-optimKwargs OPTIMKWARGS [OPTIMKWARGS ...]]\n",
            "       [-optim_separate OPTIM_SEPARATE [OPTIM_SEPARATE ...]]\n",
            "       [-scheduler SCHEDULER [SCHEDULER ...]]\n",
            "       [-scheduler_warmup_steps SCHEDULER_WARMUP_STEPS [SCHEDULER_WARMUP_STEPS ...]]\n",
            "       [-gamma GAMMA [GAMMA ...]]\n",
            "       [-angles ANGLES [ANGLES ...]]\n",
            "       [-config CONFIG [CONFIG ...]]\n",
            "       [-script SCRIPT [SCRIPT ...]]\n",
            "       [-prequel PREQUEL [PREQUEL ...]]\n",
            "       [-sample_all_styles SAMPLE_ALL_STYLES [SAMPLE_ALL_STYLES ...]]\n",
            "       [-mix MIX [MIX ...]]\n",
            "       [-clean_render CLEAN_RENDER [CLEAN_RENDER ...]]\n",
            "       [-render_list RENDER_LIST [RENDER_LIST ...]]\n",
            "       [-render RENDER [RENDER ...]]\n",
            "       [-render_text RENDER_TEXT [RENDER_TEXT ...]]\n",
            "       [-render_transparent RENDER_TRANSPARENT [RENDER_TRANSPARENT ...]]\n",
            "       [-transforms TRANSFORMS [TRANSFORMS ...]]\n",
            "       [-cpu CPU [CPU ...]]\n",
            "       [-mem MEM [MEM ...]]\n",
            "render.py: error: argument -speaker: invalid literal_eval value: 'oliver'\n"
          ]
        }
      ],
      "source": [
        "!python render.py \\\n",
        "-render 20 \\\n",
        "-render_text 0 \\\n",
        "-path2data ../data \\\n",
        "-path2outdata save \\\n",
        "-cuda 0 \\\n",
        "-load save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_\\[\\'seth\\',\\ \\'oliver\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5MtdRfUqLEs"
      },
      "outputs": [],
      "source": [
        "!python render.py \\\n",
        "-render 20\n",
        "-load save/pretrained_models/attribute/exp_3669_cpk_s2g_gst_eviltwin15_speaker_\\[\\'seth\\',\\ \\'oliver\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_eviltwin15_weights.p \\\n",
        "-render_text 0 ## if 1, render text on the video as well.\n",
        "-path2data ../data ## path to data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/mix-stage/src/save/pretrained_models/multi-speaker/exp_3663_cpk_JointLateClusterSoftStyle4_G_speaker_\\[\\'corden\\',\\ \\'lec_cosmic\\',\\ \\'ytch_prof\\',\\ \\'oliver\\',\\ \\'ellen\\',\\ \\'noah\\',\\ \\'lec_evol\\',\\ \\'maher\\'\\]_model_JointLateClusterSoftStyle4_G_note_s2g_gst_mixgan15 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "Sw609d0wuBwP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1BUYIONbQ5YM3zE9k2VIxdrn-bt-jKive",
      "authorship_tag": "ABX9TyPw2NscB0A+TEHlSuo+mFZe",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}